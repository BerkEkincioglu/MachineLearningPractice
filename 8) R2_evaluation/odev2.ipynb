{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('maaslar_yeni.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,2:5].values\n",
    "y = df.iloc[:,5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                                 OLS Regression Results                                \n=======================================================================================\nDep. Variable:                      y   R-squared (uncentered):                   0.903\nModel:                            OLS   Adj. R-squared (uncentered):              0.892\nMethod:                 Least Squares   F-statistic:                              83.89\nDate:                Sun, 05 Apr 2020   Prob (F-statistic):                    8.38e-14\nTime:                        09:15:53   Log-Likelihood:                         -295.74\nNo. Observations:                  30   AIC:                                      597.5\nDf Residuals:                      27   BIC:                                      601.7\nDf Model:                           3                                                  \nCovariance Type:            nonrobust                                                  \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nx1          2494.8107    256.145      9.740      0.000    1969.244    3020.377\nx2             1.3531    318.990      0.004      0.997    -653.161     655.867\nx3           -26.5687     33.657     -0.789      0.437     -95.626      42.489\n==============================================================================\nOmnibus:                        0.440   Durbin-Watson:                   1.617\nProb(Omnibus):                  0.803   Jarque-Bera (JB):                0.573\nSkew:                           0.109   Prob(JB):                        0.751\nKurtosis:                       2.359   Cond. No.                         23.7\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.903</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.892</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   83.89</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sun, 05 Apr 2020</td> <th>  Prob (F-statistic):</th>          <td>8.38e-14</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>09:15:53</td>     <th>  Log-Likelihood:    </th>          <td> -295.74</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th>          <td>   597.5</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    27</td>      <th>  BIC:               </th>          <td>   601.7</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>x1</th> <td> 2494.8107</td> <td>  256.145</td> <td>    9.740</td> <td> 0.000</td> <td> 1969.244</td> <td> 3020.377</td>\n</tr>\n<tr>\n  <th>x2</th> <td>    1.3531</td> <td>  318.990</td> <td>    0.004</td> <td> 0.997</td> <td> -653.161</td> <td>  655.867</td>\n</tr>\n<tr>\n  <th>x3</th> <td>  -26.5687</td> <td>   33.657</td> <td>   -0.789</td> <td> 0.437</td> <td>  -95.626</td> <td>   42.489</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 0.440</td> <th>  Durbin-Watson:     </th> <td>   1.617</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.803</td> <th>  Jarque-Bera (JB):  </th> <td>   0.573</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.109</td> <th>  Prob(JB):          </th> <td>   0.751</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.359</td> <th>  Cond. No.          </th> <td>    23.7</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "#backward elemination\n",
    "import statsmodels.api as sm \n",
    "model = sm.OLS(lr.predict(x),x)\n",
    "model.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "lr2 = LinearRegression()\n",
    "pf = PolynomialFeatures(degree=4)\n",
    "lr.fit(x,pf.fit_transform(x))"
   ]
  }
 ]
}